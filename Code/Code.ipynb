{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jGPp5Wq3C94A"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "healthfc_df = pd.read_csv(\"healthFC_annotated.csv\")\n",
        "hfc_questions = healthfc_df.en_claim.tolist()\n",
        "hfc_labels = healthfc_df.label.tolist()\n"
      ],
      "metadata": {
        "id": "xkvB2UC8g2Z_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open(\"BioASQ-train-yesno-7b.json\", \"r\") as f:\n",
        "    bioasq_content = json.load(f)\n",
        "\n",
        "bioasq_questions = list()\n",
        "bioasq_answers = list()\n",
        "for qid in range(len(bioasq_content[\"data\"][0][\"paragraphs\"])):\n",
        "    question = bioasq_content[\"data\"][0][\"paragraphs\"][qid][\"qas\"][0][\"question\"]\n",
        "    answer = bioasq_content[\"data\"][0][\"paragraphs\"][qid][\"qas\"][0][\"answers\"]\n",
        "    if question not in bioasq_questions:\n",
        "        bioasq_questions.append(question)\n",
        "        bioasq_answers.append(answer)\n"
      ],
      "metadata": {
        "id": "E0Espmlog5zh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install retriv\n",
        "!pip install dill\n",
        "!pip install torch\n",
        "!pip install sentence_transformers\n",
        "!pip install scikit-learn\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "Nz-bitRODEBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "txt file gen. After this code, merge it with true_label given in datasets"
      ],
      "metadata": {
        "id": "2WbjpuevSg-3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import dill as pickle\n",
        "from retriv import SparseRetriever\n",
        "\n",
        "sr = SparseRetriever(\n",
        "  index_name=\"pubmed-index\",\n",
        "  model=\"bm25\",\n",
        "  min_df=10,\n",
        "  tokenizer=\"whitespace\",\n",
        "  stemmer=\"english\",\n",
        "  stopwords=\"english\",\n",
        "  do_lowercasing=True,\n",
        "  do_ampersand_normalization=True,\n",
        "  do_special_chars_normalization=True,\n",
        "  do_acronyms_normalization=True,\n",
        "  do_punctuation_removal=True,\n",
        ")\n",
        "\n",
        "corpus_path = \"/content/drive/MyDrive/pubmed_landscape_abstracts.csv\"\n",
        "\n",
        "import time\n",
        "start = time.time()\n",
        "\n",
        "sr = sr.index_file(\n",
        "  path=corpus_path,\n",
        "  show_progress=True,\n",
        "  callback=lambda doc: {\n",
        "    \"id\": doc[\"PMID\"],\n",
        "    \"text\": doc[\"AbstractText\"],\n",
        "    }\n",
        "  )\n",
        "\n",
        "with open('/content/drive/MyDrive/Tesi/Prove_codice_/pickled1_sr', 'wb') as file:\n",
        "    pickle.dump(sr, file)"
      ],
      "metadata": {
        "id": "3JwOd5msDSxt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import torch\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "\n",
        "start_idx = 0  # start\n",
        "end_idx = 1048  # end\n",
        "\n",
        "\n",
        "with open('/content/drive/MyDrive/pickled_sr', 'rb') as file:\n",
        "    inverted_index = pickle.load(file)\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/healthFC_annotated.csv\")\n",
        "claims = df.en_claim.tolist()\n",
        "labels = df.label.tolist()\n",
        "\n",
        "\n",
        "query_list = []\n",
        "for idx, claim in enumerate(claims[start_idx:end_idx]):\n",
        "    claim = claim.lower()\n",
        "    query_list.append({\"id\": str(idx + start_idx), \"text\": claim})\n",
        "\n",
        "\n",
        "results = inverted_index.msearch(\n",
        "  queries=query_list,\n",
        "  cutoff=20,\n",
        ")\n",
        "\n",
        "# Carica il file CSV degli abstract\n",
        "abstracts = pd.read_csv(\"/content/drive/MyDrive/abstract_merged.csv\")\n",
        "\n",
        "# Crea un dizionario di mapping dagli ID degli abstract ai loro testi\n",
        "abstract_dict = pd.Series(abstracts.AbstractText.values, index=abstracts.PMID.astype(str)).to_dict()\n",
        "\n",
        "# Rimappa tutti gli ID dei documenti dai risultati.\n",
        "remapped_all_ids = []\n",
        "for claim_id, document_results in results.items():\n",
        "    remapped_ids = []\n",
        "    for doc_id, score in document_results.items():\n",
        "        if doc_id in abstract_dict:\n",
        "            remapped_ids.append(doc_id)\n",
        "        else:\n",
        "            print(f\"Skipping invalid doc_id: {doc_id}\")\n",
        "    remapped_all_ids.append(remapped_ids)\n",
        "\n",
        "claim_sentences = []\n",
        "for ids in remapped_all_ids:\n",
        "    all_sentences = []\n",
        "    for doc_id in ids:\n",
        "        abstract = abstract_dict[doc_id]\n",
        "        sentences = sent_tokenize(abstract)\n",
        "        all_sentences.append((doc_id, sentences))\n",
        "    claim_sentences.append(all_sentences)\n",
        "\n",
        "# Carica il modello di trasformatore di frasi per selezionare le frasi di prova.\n",
        "model = SentenceTransformer('copenlu/spiced')\n",
        "print(\"loaded sentence model!\")\n",
        "\n",
        "# Trova le prime 3 frasi più simili alla query da ciascun documento, per condensarlo nelle parti più importanti.\n",
        "top_sentences = []\n",
        "for idx in range(start_idx, min(end_idx, len(claims))):\n",
        "    claim = claims[idx]\n",
        "    print(f\"Processing claim {idx + 1}/{len(claims)}\")\n",
        "\n",
        "    if idx - start_idx >= len(claim_sentences):\n",
        "        print(f\"Warning: claim index {idx} out of range\")\n",
        "        continue\n",
        "\n",
        "    sents_per_doc = claim_sentences[idx - start_idx]\n",
        "\n",
        "    doc_top_sentences = []\n",
        "    for doc_id, sents in sents_per_doc:\n",
        "        sents_embeddings = model.encode(sents, convert_to_tensor=True)\n",
        "        claim_embedding = model.encode(claim, convert_to_tensor=True)\n",
        "        cos_scores = util.cos_sim(claim_embedding, sents_embeddings)[0]\n",
        "\n",
        "        new_k = 3\n",
        "        if len(sents) < 3:\n",
        "            new_k = len(sents)\n",
        "\n",
        "        top_results = torch.topk(cos_scores, k=new_k)\n",
        "\n",
        "        np_results = top_results[1].detach().cpu().numpy()\n",
        "        np_results = np_results[np_results < len(sents)]  # Filtra gli indici fuori range\n",
        "        doc_top_sentences.append((doc_id, np_results))\n",
        "    top_sentences.append(doc_top_sentences)\n",
        "\n",
        "selected_sentences = []\n",
        "for doc_sents, doc_top_sents in zip(claim_sentences, top_sentences):\n",
        "    doc_selected_sents = []\n",
        "    for (doc_id, sents), (top_doc_id, top) in zip(doc_sents, doc_top_sents):\n",
        "        selected_sents = np.array(sents)[top]\n",
        "        doc_selected_sents.append((doc_id, selected_sents))\n",
        "    selected_sentences.append(doc_selected_sents)\n",
        "\n",
        "# Crea una lista congiunta di claims concatenati e prove, in forma di \"claim [SEP] evidence1 evidence2 evidence3\"\n",
        "joint_list = []\n",
        "for idx in range(start_idx, min(end_idx, len(claims))):\n",
        "    claim = claims[idx]\n",
        "    for doc_id, sents in selected_sentences[idx - start_idx]:\n",
        "        joint = claim + \" [SEP] \"\n",
        "        for s in sents:\n",
        "            joint += s + f\" [{doc_id}] \"\n",
        "        joint_list.append(joint)\n",
        "\n",
        "output_filename = f\"/content/drive/MyDrive/20_sentences_SciFact.txt\"\n",
        "with open(output_filename, \"w\") as f:\n",
        "    for line in joint_list:\n",
        "        f.write(line)\n",
        "        f.write(\"\\n\")\n",
        "\n",
        "with open(output_filename, \"r\") as f:\n",
        "    lines = f.readlines()\n",
        "    flatlines = []\n",
        "    for l in lines:\n",
        "        l = l.strip()\n",
        "        if \"[SEP]\" in l:\n",
        "            flatlines.append(l)\n",
        "\n",
        "print(\"Processing complete!\")"
      ],
      "metadata": {
        "id": "ogwSrL3ODTlb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from collections import defaultdict\n",
        "\n",
        "# Leggere il file di testo\n",
        "file_path = '/content/drive/MyDrive/20_sentences_healthFC.txt'\n",
        "with open(file_path, 'r') as file:\n",
        "    lines = file.readlines()\n",
        "\n",
        "# Dizionario per raggruppare le frasi e le relative sentence\n",
        "frase_dict = defaultdict(list)\n",
        "\n",
        "# Parsing delle linee\n",
        "for line in lines:\n",
        "    if '[SEP]' in line:\n",
        "        # Separare la frase e la sentence\n",
        "        frase, sentence = line.split('[SEP]')\n",
        "        sentence = sentence.strip()\n",
        "\n",
        "        # Aggiungere la sentence al dizionario\n",
        "        frase_dict[frase.strip()].append(sentence)\n",
        "\n",
        "# Scrittura nel file CSV\n",
        "csv_file_path = '/content/drive/MyDrive/Health_fc_sentences_true_label.csv'\n",
        "with open(csv_file_path, 'w', newline='') as csvfile:\n",
        "    csvwriter = csv.writer(csvfile)\n",
        "    # Scrivere l'intestazione\n",
        "    csvwriter.writerow(['Frase', 'Sentences Concatenate'])\n",
        "\n",
        "    # Scrivere i dati raggruppati\n",
        "    for frase, sentences in frase_dict.items():\n",
        "        sentences_concat = ' '.join(sentences)\n",
        "        csvwriter.writerow([frase, sentences_concat])\n",
        "\n",
        "print(f\"File CSV generato: {csv_file_path}\")"
      ],
      "metadata": {
        "id": "0VBuT4JLHRt8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dense"
      ],
      "metadata": {
        "id": "kC9W807jCFkx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import logging\n",
        "\n",
        "# Imposta logging per monitorare il processo\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')\n",
        "\n",
        "# File paths\n",
        "corpus_path = \"/content/drive/MyDrive/Scifact_elaborazione/corpus_train.csv\"\n",
        "questions_path = \"/content/drive/MyDrive/Scifact_elaborazione/claims_train.csv\"\n",
        "output_path = \"retrieval_results_dense_scifact.csv\"\n",
        "\n",
        "# Caricamento dei dati\n",
        "logging.info(\"Caricamento dei file CSV...\")\n",
        "corpus = pd.read_csv(corpus_path)\n",
        "queries = pd.read_csv(questions_path)\n",
        "\n",
        "# Assicurati che le colonne esistano\n",
        "assert 'abstract' in corpus.columns, \"Il corpus deve avere una colonna 'abstract'.\"\n",
        "assert 'claim' in queries.columns, \"Il file delle query deve avere una colonna 'claim'.\"\n",
        "\n",
        "# Prepara i documenti e le query\n",
        "documents = corpus['abstract'].dropna().tolist()\n",
        "claims = queries['claim'].dropna().tolist()\n",
        "\n",
        "# Controllo dei documenti\n",
        "if not documents:\n",
        "    raise ValueError(\"La lista dei documenti è vuota.\")\n",
        "if not claims:\n",
        "    raise ValueError(\"La lista delle query è vuota.\")\n",
        "\n",
        "# Verifica della GPU\n",
        "if not torch.cuda.is_available():\n",
        "    logging.error(\"GPU non disponibile. Assicurati di avere una GPU configurata correttamente.\")\n",
        "    raise EnvironmentError(\"GPU non disponibile.\")\n",
        "device = 'cuda'\n",
        "\n",
        "# Caricamento del modello SBERT\n",
        "logging.info(\"Caricamento del modello SBERT...\")\n",
        "model = SentenceTransformer('multi-qa-MiniLM-L6-cos-v1', device=device)\n",
        "\n",
        "# Funzione per codificare i documenti in batch\n",
        "def encode_in_batches(model, documents, batch_size=32):\n",
        "    logging.info(\"Codifica dei documenti in batch...\")\n",
        "    dataloader = DataLoader(documents, batch_size=batch_size)\n",
        "    embeddings = []\n",
        "    for batch in dataloader:\n",
        "        batch_embeddings = model.encode(batch, convert_to_tensor=True, device=device)\n",
        "        embeddings.append(batch_embeddings)\n",
        "    return torch.cat(embeddings)\n",
        "\n",
        "# Codifica dei documenti\n",
        "logging.info(\"Codifica dei documenti...\")\n",
        "document_embeddings = encode_in_batches(model, documents)\n",
        "\n",
        "# Lista per i risultati finali\n",
        "results = []\n",
        "\n",
        "# Iterazione sulle query\n",
        "logging.info(\"Avvio del retrieval denso...\")\n",
        "for idx, query in enumerate(claims):\n",
        "    logging.info(f\"Processamento query {idx + 1}/{len(claims)}: {query}\")\n",
        "\n",
        "    # Codifica della query\n",
        "    query_embedding = model.encode(query, convert_to_tensor=True, device=device)\n",
        "\n",
        "    # Calcolo dei punteggi di similarità\n",
        "    dense_scores = util.cos_sim(query_embedding, document_embeddings).squeeze().tolist()\n",
        "\n",
        "    # Ordina i documenti in base ai punteggi\n",
        "    ranked_indices = np.argsort(dense_scores)[::-1]\n",
        "    ranked_docs = [(documents[i], dense_scores[i]) for i in ranked_indices]\n",
        "\n",
        "    # Salva i top 5 risultati per la query\n",
        "    for rank, (doc, score) in enumerate(ranked_docs[:5], start=1):\n",
        "        results.append({\n",
        "            'query': query,\n",
        "            'document': doc,\n",
        "            'score': score,\n",
        "            'rank': rank\n",
        "        })\n",
        "\n",
        "# Salva i risultati in un file CSV\n",
        "logging.info(\"Salvataggio dei risultati in un file CSV...\")\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df.to_csv(output_path, index=False)\n",
        "\n",
        "logging.info(f\"Processo completato. Risultati salvati in: {output_path}\")\n"
      ],
      "metadata": {
        "id": "KzhUE9V_CD61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CSV CREATION WITH CLAIM, SENTENCES AND TRUE LABEL (given in the dataset folder)"
      ],
      "metadata": {
        "id": "FHqZXq-dIhgt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   BioASQ_sentences_true_label.csv\n",
        "2.   Health_fc_sentences_true_label.csv\n"
      ],
      "metadata": {
        "id": "kX07vobtMS9f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Percorso del file CSV\n",
        "csv_file_path = '/content/drive/MyDrive/BioASQ_sentences_true_label.csv'\n",
        "\n",
        "# Leggere il file CSV\n",
        "df = pd.read_csv(csv_file_path)"
      ],
      "metadata": {
        "id": "n8xSRIb5OXBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Percorso del file CSV\n",
        "csv_file_path = '/content/drive/MyDrive/Health_fc_sentences_true_label.csv'\n",
        "\n",
        "# Leggere il file CSV\n",
        "df = pd.read_csv(csv_file_path)"
      ],
      "metadata": {
        "id": "z4SHQEwFOXor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets pandas sentence_transformers\n",
        "!pip install -U transformers\n",
        "# Install below if using GPU\n",
        "!pip install accelerate\n",
        "!pip install chromadb tqdm fireworks-ai python-dotenv pandas\n",
        "!pip install sentence-transformers\n",
        "import fireworks.client\n",
        "import os\n",
        "import dotenv\n",
        "import chromadb\n",
        "import json\n",
        "from tqdm.auto import tqdm\n",
        "import pandas as pd\n",
        "import random\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import pandas as pd\n",
        "\n",
        "fireworks.client.api_key = \"\"\n",
        "dotenv.load_dotenv()\n",
        "\n",
        "mixtral_llm = \"mixtral-8x22b-instruct\"\n",
        "\n",
        "def get_completion(prompt, model=None, max_tokens=50):\n",
        "\n",
        "    fw_model_dir = \"accounts/fireworks/models/\"\n",
        "\n",
        "    model = fw_model_dir + model\n",
        "\n",
        "    completion = fireworks.client.Completion.create(\n",
        "        model=model,\n",
        "        prompt=prompt,\n",
        "        max_tokens=max_tokens,\n",
        "        temperature=0.3\n",
        "    )\n",
        "\n",
        "    return completion.choices[0].text"
      ],
      "metadata": {
        "id": "EfCYunnPMYuh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fireworks.ai version"
      ],
      "metadata": {
        "id": "VfJHNjbJOyWm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "def add_to_dataframe(query, Risposta):\n",
        "    # Trova la label nella risposta usando una regex\n",
        "    label_match = re.search(r\"Label: (\\w+)\", Risposta)\n",
        "    if label_match:\n",
        "        label = label_match.group(1)  # Estrai la label\n",
        "        justification = Risposta[label_match.end():].strip()  # Tutto ciò che segue la label è la justification\n",
        "        claim = query.strip()  # Il claim è semplicemente la query data\n",
        "        new_row = pd.DataFrame([[claim, label, justification]], columns=[\"Claim\", \"Predicted label\", \"Justification\"])\n",
        "        global df1\n",
        "        df1 = pd.concat([df1, new_row], ignore_index=True)\n",
        "\n",
        "start_index = 1  # Modifica questo valore a tuo piacimento\n",
        "\n",
        "num_rows = 2 # Numero di righe da considerare\n",
        "\n",
        "for index in range(start_index, start_index + num_rows):\n",
        "    query = df.loc[index, 'Frase']\n",
        "    results = df.loc[index, 'Sentences Concatenate']\n",
        "\n",
        "    # Costruisci il prompt template con query e results prelevati\n",
        "    prompt_template = f'''[INST]  <<SYS>>\n",
        "\n",
        "    You are a helpful, respectful and honest Doctor. Always answer as helpfully as possible using the context text provided. Try to give an explanation based on {results} to the question {query}. elaborate the context to generate a new information.\n",
        "\n",
        "    Use only the knowledge in results to answer.\n",
        "\n",
        "    Answer describing in a scentific way. Be formal during the answer. Use the third person.\n",
        "\n",
        "    Answer without mentioning the context. Use it but don't refer to it in the text\n",
        "\n",
        "    to answer, use max 200 word\n",
        "\n",
        "    with the answer, gives a line like: \"Label:\". Always put Label as first. After Label, give the justification\n",
        "    Label can be yes, no, NEI, where yes: claim is true. no: claim is false. NEI: not enough information.\n",
        "    <<SYS>>\n",
        "\n",
        "    \"\"\"CONTEXT:/n/n {results}/n\n",
        "\n",
        "    Question: {query} [/INST]\n",
        "\n",
        "    '''\n",
        "\n",
        "    responses = get_completion(prompt_template, model=mixtral_llm, max_tokens=400)\n",
        "    Risposta = ''.join([str(r) for r in responses])\n",
        "\n",
        "    # Stampa la risposta per ogni iterazione\n",
        "    print(\"\")\n",
        "    print(Risposta)\n",
        "    try:\n",
        "      df1\n",
        "    except NameError:\n",
        "      df1 = pd.DataFrame(columns=[\"Claim\", \"Predicted label\", \"Justification\"])\n",
        "    # Esempio di utilizzo\n",
        "    add_to_dataframe(query, Risposta)"
      ],
      "metadata": {
        "id": "R7THaaoVOh2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Datasets with Justification\n",
        "\n",
        "1.   HealthFc_Frase_Predicted label_Justification_Sentences Concatenate_True label.csv\n",
        "2.   BioASQ_Frase_Predicted label_Justification_Sentences Concatenate_True label.csv\n",
        "\n"
      ],
      "metadata": {
        "id": "J9Tkwug1PgGA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Definire il dizionario di mapping inverso\n",
        "label_mapping_inverse = {0: 'Yes', 1: 'NEI', 2: 'No'}\n",
        "\n",
        "# Applicare il mapping inverso alla colonna 'True label'\n",
        "selected_columns['True label'] = selected_columns['True label'].map(label_mapping_inverse)"
      ],
      "metadata": {
        "id": "if5atSJHQRO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Calcolo delle metriche\n",
        "precision = precision_score(selected_columns['True label'], selected_columns['Predicted label'], average='macro')\n",
        "recall = recall_score(selected_columns['True label'], selected_columns['Predicted label'], average='macro')\n",
        "f1 = f1_score(selected_columns['True label'], selected_columns['Predicted label'], average='macro')\n",
        "\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')"
      ],
      "metadata": {
        "id": "wBxrE3kXQT-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#For single class\n",
        "from sklearn.metrics import precision_score\n",
        "\n",
        "# Definizione delle etichette\n",
        "labels = ['Yes', 'NEI', 'No']\n",
        "\n",
        "# Calcolo delle precisioni per ogni classe\n",
        "precision_per_class = precision_score(selected_columns['True label'], selected_columns['Predicted label'], labels=labels, average=None)\n",
        "\n",
        "# Stampare le precisioni per ogni classe\n",
        "for label, precision in zip(labels, precision_per_class):\n",
        "    print(f'Precision for class {label}: {precision:.4f}')"
      ],
      "metadata": {
        "id": "QEcrOYldQhMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classification with MoritzLaurer/deberta-v3-large-zeroshot-v1.1-all-33 to avoid allucination"
      ],
      "metadata": {
        "id": "pOf5lFT2QuTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Always load the right csv before"
      ],
      "metadata": {
        "id": "Pm2TZHMLcfg_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Percorso del file CSV\n",
        "csv_file_path = '/content/drive/MyDrive/BioASQ_Frase_Predicted_label_Justification_Sentences Concatenate_True label.csv'\n",
        "\n",
        "# Leggere il file CSV\n",
        "df = pd.read_csv(csv_file_path)"
      ],
      "metadata": {
        "id": "R0a8w-HR7DPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from transformers import pipeline\n",
        "\n",
        "# Set start and end indices\n",
        "start_idx = 0\n",
        "end_idx = 749\n",
        "\n",
        "# Configure the zero-shot classifier\n",
        "zeroshot_classifier = pipeline(\"zero-shot-classification\", model=\"MoritzLaurer/deberta-v3-large-zeroshot-v1.1-all-33\")\n",
        "\n",
        "# Function to generate justifications\n",
        "def generate_justification(row):\n",
        "    claim = row['Frase']\n",
        "    sentences=['Sentence_concatenate']\n",
        "    justifications = row[\"Justification\"]\n",
        "    true_label = row['True label']\n",
        "    predicted_label = row['Predicted label']\n",
        "    Class = [\"True\", \"False\", \"NEI\"]\n",
        "    justification1 = f'\"prediction: {predicted_label}\" for: justificatoin used for the prediction \"{justifications}\" with sentencies {sentences}'\n",
        "    max_length = 512 # Some buffer for tokens\n",
        "    if len(justification1) > max_length:\n",
        "        justification1 = justification1[:max_length]\n",
        "    output = zeroshot_classifier(claim, Class, hypothesis_template=\"The claim is '{}' for: \" + justification1, multi_label=False)\n",
        "\n",
        "    final_justification = f'{output}. Predicted label was {predicted_label}. True label was {true_label}'\n",
        "    return final_justification\n",
        "\n",
        "# Iterate through the DataFrame rows and generate justifications\n",
        "file_path = \"/content/drive/MyDrive/output_senza_sentences.txt\"\n",
        "\n",
        "for idx in range(start_idx, end_idx + 1):\n",
        "    row = result.iloc[idx]\n",
        "    validità = generate_justification(row)\n",
        "    output_string = f\"row {idx}: {validità}\"\n",
        "   # print(output_string)\n",
        "\n",
        "    # Write the result to the file immediately\n",
        "    with open(file_path, 'a') as file:\n",
        "        file.write(output_string + \"\\n\")\n",
        "        print(\"stringa \")\n",
        "        print(idx)"
      ],
      "metadata": {
        "id": "nhsjrG72Q6fz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Results.txt for this phase"
      ],
      "metadata": {
        "id": "pZmxY61xZxjt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Funzione per estrarre le informazioni da una riga di testo\n",
        "def parse_line(line):\n",
        "    sequence_match = re.search(r\"'sequence': '(.*?)'\", line)\n",
        "    label_match = re.search(r\"'labels': \\['(.*?)', '(.*?)'\\]\", line)\n",
        "    true_label_match = re.search(r'True label was (Yes|No)', line)\n",
        "\n",
        "    sequence = sequence_match.group(1) if sequence_match else ''\n",
        "    label = label_match.group(1) if label_match else ''\n",
        "    true_label = true_label_match.group(1) if true_label_match else ''\n",
        "\n",
        "    return sequence, label, true_label\n",
        "\n",
        "# Leggi il file di testo\n",
        "input_file = '/content/drive/MyDrive/output.txt' #Change here to read the results (FOR BIOASQ RES)\n",
        "\n",
        "data = []\n",
        "\n",
        "with open(input_file, 'r') as infile:\n",
        "    for line in infile:\n",
        "        sequence, label, true_label = parse_line(line)\n",
        "        data.append([sequence, label, true_label])\n",
        "\n",
        "# Crea un DataFrame\n",
        "df = pd.DataFrame(data, columns=['sequence', 'label', 'True Label'])\n",
        "\n",
        "# Mostra il DataFrame\n",
        "print(df)"
      ],
      "metadata": {
        "id": "n7878et_Z2tr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For health_fc"
      ],
      "metadata": {
        "id": "46VgMhydaA2i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Funzione per estrarre le informazioni da una riga di testo\n",
        "def parse_line(line):\n",
        "    sequence_match = re.search(r\"'sequence': '(.*?)'\", line)\n",
        "    labels_match = re.search(r\"'labels': \\[(.*?)\\]\", line)\n",
        "    true_label_match = re.search(r'True label was (\\d+)', line)\n",
        "    predicted_label_match = re.search(r'Predicted label was (\\w+)', line)\n",
        "\n",
        "    sequence = sequence_match.group(1) if sequence_match else ''\n",
        "    labels = labels_match.group(1).replace(\"'\", \"\").split(', ') if labels_match else []\n",
        "    true_label = int(true_label_match.group(1)) if true_label_match else -1\n",
        "    predicted_label = predicted_label_match.group(1) if predicted_label_match else ''\n",
        "\n",
        "    return sequence, labels, true_label, predicted_label\n",
        "\n",
        "# Leggi il file di testo\n",
        "input_file = '/content/drive/MyDrive/output.txt'\n",
        "\n",
        "data = []\n",
        "\n",
        "with open(input_file, 'r') as infile:\n",
        "    for line in infile:\n",
        "        sequence, labels, true_label, predicted_label = parse_line(line)\n",
        "        data.append([sequence, labels, true_label, predicted_label])\n",
        "\n",
        "# Crea un DataFrame\n",
        "df = pd.DataFrame(data, columns=['sequence', 'labels', 'True Label', 'Predicted Label'])\n",
        "\n",
        "# Mostra il DataFrame\n",
        "print(df)"
      ],
      "metadata": {
        "id": "OU9AMT99aCVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcolare precision, recall e F1-score\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "precision = precision_score(df['True Label'], df['Predicted Label'], pos_label='Yes', average='weighted')\n",
        "recall = recall_score(df['True Label'], df['Predicted Label'], pos_label='Yes', average='weighted')\n",
        "f1 = f1_score(df['True Label'], df['Predicted Label'], pos_label='Yes', average='weighted')\n",
        "\n",
        "# Visualizzare i risultati\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-score: {f1:.4f}\")"
      ],
      "metadata": {
        "id": "YOntJYJ8aLkI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fine_tuning"
      ],
      "metadata": {
        "id": "Z5E5TV-YaSXM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets torch\n",
        "!pip install scikit-learn pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cluDKaO0aVbG",
        "outputId": "fd71390c-77a9-4dc6-b2e5-0fba86628b5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.21.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.5)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.4)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Collecting pyarrow>=15.0.0 (from datasets)\n",
            "  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.2)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.3.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.7.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Downloading datasets-2.21.0-py3-none-any.whl (527 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m527.3/527.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m237.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "Installing collected packages: xxhash, pyarrow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, dill, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, nvidia-cusolver-cu12, datasets\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-2.21.0 dill-0.3.8 multiprocess-0.70.16 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105 pyarrow-17.0.0 xxhash-3.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code to split in train, validation and test set"
      ],
      "metadata": {
        "id": "Cjk8AaG1aiGR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Prima, suddividiamo in train+validation e test\n",
        "train_val_df, test_df = train_test_split(df, test_size=0.2, stratify=df['True Label'], random_state=42)\n",
        "\n",
        "# Poi, suddividiamo train+validation in train e validation\n",
        "train_df, val_df = train_test_split(train_val_df, test_size=0.25, stratify=train_val_df['True Label'], random_state=42)\n",
        "# Nota: 0.25 * 0.8 = 0.2, quindi il set di validazione sarà il 20% del totale"
      ],
      "metadata": {
        "id": "N2i4nkjxaX75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_merged['True Label'].value_counts())\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Suddivisione train+validation e test\n",
        "train_val_df, test_df = train_test_split(df_merged, test_size=0.2, stratify=df['True Label'], random_state=42)\n",
        "\n",
        "# Suddivisione train+validation in train e validation\n",
        "train_df, val_df = train_test_split(train_val_df, test_size=0.25, stratify=train_val_df['True Label'], random_state=42)\n",
        "# Verifica della distribuzione\n",
        "print(\"Distribuzione delle etichette nel training set:\")\n",
        "print(train_df['True Label'].value_counts())\n",
        "\n",
        "print(\"Distribuzione delle etichette nel validation set:\")\n",
        "print(val_df['True Label'].value_counts())\n",
        "\n",
        "print(\"Distribuzione delle etichette nel test set:\")\n",
        "print(test_df['True Label'].value_counts())"
      ],
      "metadata": {
        "id": "TEBefYQcad1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/MyDrive/Fine_Tuning/train1.csv'\n",
        "file_path1 = '/content/drive/MyDrive/Fine_Tuning/val1.csv'\n",
        "file_path2 = '/content/drive/MyDrive/Fine_Tuning/test1.csv'\n",
        "# Salva il DataFrame in un file CSV\n",
        "train_df.to_csv(file_path, index=False)\n",
        "val_df.to_csv(file_path1, index=False)\n",
        "test_df.to_csv(file_path2, index=False)\n",
        "print(f\"DataFrame salvato con successo in: {file_path}\")"
      ],
      "metadata": {
        "id": "eMLDJX64avbU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "BIOASQ\n",
        "1.   train\n",
        "2.   val\n",
        "3.   test\n",
        "\n",
        "HealthFC\n",
        "1.   train1\n",
        "2.   val1\n",
        "3.   test1"
      ],
      "metadata": {
        "id": "bPzHdcilauEL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/MyDrive/Fine_Tuning/train1.csv'\n",
        "file_path1 = '/content/drive/MyDrive/Fine_Tuning/val1.csv'\n",
        "file_path2 = '/content/drive/MyDrive/Fine_Tuning/test1.csv'\n",
        "#train1 sono 3 classi\n",
        "train_df = pd.read_csv(file_path)\n",
        "val_df = pd.read_csv(file_path1)\n",
        "test_df = pd.read_csv(file_path2)"
      ],
      "metadata": {
        "id": "CXl15AqTatVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BIOASQ"
      ],
      "metadata": {
        "id": "m2ttn4qhbJnJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np  # Importare NumPy\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datasets import Dataset, DatasetDict\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "\n",
        "# Convertire i DataFrame in Dataset di Hugging Face\n",
        "def convert_to_dataset(df):\n",
        "    return Dataset.from_pandas(df)\n",
        "\n",
        "# Supponiamo che train_df, val_df, e test_df siano già definiti\n",
        "train_dataset = convert_to_dataset(train_df)\n",
        "val_dataset = convert_to_dataset(val_df)\n",
        "test_dataset = convert_to_dataset(test_df)\n",
        "\n",
        "# Creare un DatasetDict\n",
        "dataset = DatasetDict({\n",
        "    'train': train_dataset,\n",
        "    'validation': val_dataset,\n",
        "    'test': test_dataset\n",
        "})\n",
        "\n",
        "# Preprocessare e tokenizzare\n",
        "model_name = \"MoritzLaurer/deberta-v3-large-zeroshot-v1.1-all-33\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    # Concatenare Claim e Justification e mappare le etichette\n",
        "    texts = [claim + \" \" + justification for claim, justification in zip(examples['Claim'], examples['Justification'])]\n",
        "    labels = [1 if label == 'Yes' else 0 for label in examples['True label']]\n",
        "    encodings = tokenizer(texts, padding=\"max_length\", truncation=True)\n",
        "    encodings['labels'] = labels\n",
        "    return encodings\n",
        "\n",
        "encoded_dataset = dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "# Configurare il modello\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
        "\n",
        "# Definire gli argomenti di training\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=2,\n",
        "    per_device_eval_batch_size=2,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.20,\n",
        "    gradient_accumulation_steps=8,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\",\n",
        "    save_strategy=\"epoch\"\n",
        ")\n",
        "\n",
        "# Definire la funzione di metriche\n",
        "def compute_metrics(p):\n",
        "    preds = np.argmax(p.predictions, axis=1)\n",
        "    precision = precision_score(p.label_ids, preds)\n",
        "    recall = recall_score(p.label_ids, preds)\n",
        "    f1 = f1_score(p.label_ids, preds)\n",
        "    return {'precision': precision, 'recall': recall, 'f1': f1}\n",
        "\n",
        "# Creare il Trainer con specifica della funzione di perdita\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=encoded_dataset['train'],\n",
        "    eval_dataset=encoded_dataset['validation'],\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "# Addestrare il modello\n",
        "trainer.train()\n",
        "\n",
        "# Valutazione del modello sul set di test\n",
        "metrics = trainer.evaluate(encoded_dataset['test'])\n",
        "print(\"Test set evaluation metrics:\", metrics)\n"
      ],
      "metadata": {
        "id": "-uHL1W59a_pI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "HealthFC (Bert Uncased)"
      ],
      "metadata": {
        "id": "YJLTSPbebNLR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np  # Importare NumPy\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datasets import Dataset, DatasetDict\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# Percorso della cartella\n",
        "directory = './results'\n",
        "\n",
        "# Cancellare tutti i file e le sottocartelle\n",
        "if os.path.exists(directory):\n",
        "    shutil.rmtree(directory)\n",
        "    print(f\"Tutti i contenuti della cartella '{directory}' sono stati cancellati.\")\n",
        "else:\n",
        "    print(f\"La cartella '{directory}' non esiste.\")\n",
        "\n",
        "# Ricreare la cartella (opzionale)\n",
        "os.makedirs(directory, exist_ok=True)\n",
        "print(f\"La cartella '{directory}' è stata ricreata.\")\n",
        "\n",
        "# Convertire i DataFrame in Dataset di Hugging Face\n",
        "def convert_to_dataset(df):\n",
        "    return Dataset.from_pandas(df)\n",
        "\n",
        "# Supponiamo che train_df, val_df, e test_df siano già definiti\n",
        "train_dataset = convert_to_dataset(train_df)\n",
        "val_dataset = convert_to_dataset(val_df)\n",
        "test_dataset = convert_to_dataset(test_df)\n",
        "\n",
        "# Creare un DatasetDict\n",
        "dataset = DatasetDict({\n",
        "    'train': train_dataset,\n",
        "    'validation': val_dataset,\n",
        "    'test': test_dataset\n",
        "})\n",
        "\n",
        "# Preprocessare e tokenizzare\n",
        "#model_name = \"MoritzLaurer/deberta-v3-large-zeroshot-v1.1-all-33\"\n",
        "model_name = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    texts = [claim + \" \" + justification for claim, justification in zip(examples['Claim'], examples['Justification'])]\n",
        "    labels = [0 if label == 'Yes' else 1 if label == 'NEI' else 2 for label in examples['True Label']]\n",
        "    encodings = tokenizer(texts, padding=\"max_length\", truncation=True)\n",
        "    encodings['labels'] = labels\n",
        "    return encodings\n",
        "\n",
        "encoded_dataset = dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "# Configurare il modello\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)\n",
        "\n",
        "# Definire gli argomenti di training\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=4e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=5,\n",
        "    weight_decay=0.20,\n",
        "    gradient_accumulation_steps=2,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\",\n",
        "    save_strategy=\"epoch\"\n",
        ")\n",
        "\n",
        "# Definire la funzione di metriche\n",
        "def compute_metrics(p):\n",
        "    preds = np.argmax(p.predictions, axis=1)\n",
        "    precision = precision_score(p.label_ids, preds, average='weighted')\n",
        "    recall = recall_score(p.label_ids, preds, average='weighted')\n",
        "    f1 = f1_score(p.label_ids, preds, average='weighted')\n",
        "    accuracy = accuracy_score(p.label_ids, preds)\n",
        "    return {'precision': precision, 'recall': recall, 'f1': f1, 'accuracy': accuracy}\n",
        "# Creare il Trainer con specifica della funzione di perdita\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=encoded_dataset['train'],\n",
        "    eval_dataset=encoded_dataset['validation'],\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "# Addestrare il modello\n",
        "trainer.train()\n",
        "\n",
        "# Valutazione del modello sul set di test\n",
        "metrics = trainer.evaluate(encoded_dataset['test'])\n",
        "print(\"Test set evaluation metrics:\", metrics)"
      ],
      "metadata": {
        "id": "ftjCDNkKbL2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Try with PubmedBert fine tuned"
      ],
      "metadata": {
        "id": "p_FSzUG62XNH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Healthfc"
      ],
      "metadata": {
        "id": "AJx1vCZz2cbW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "file_path = '/content/drive/MyDrive/Fine_Tuning/train1.csv'\n",
        "file_path1 = '/content/drive/MyDrive/Fine_Tuning/val1.csv'\n",
        "file_path2 = '/content/drive/MyDrive/Fine_Tuning/test1.csv'\n",
        "#train1 sono 3 classi\n",
        "train_df = pd.read_csv(file_path)\n",
        "val_df = pd.read_csv(file_path1)\n",
        "test_df = pd.read_csv(file_path2)"
      ],
      "metadata": {
        "id": "Zmh44nNZ2dVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install datasets"
      ],
      "metadata": {
        "id": "_45Ttq7S2fMA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datasets import Dataset, DatasetDict\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# Percorso della cartella\n",
        "directory = './results'\n",
        "\n",
        "# Cancellare tutti i file e le sottocartelle\n",
        "if os.path.exists(directory):\n",
        "    shutil.rmtree(directory)\n",
        "    print(f\"Tutti i contenuti della cartella '{directory}' sono stati cancellati.\")\n",
        "else:\n",
        "    print(f\"La cartella '{directory}' non esiste.\")\n",
        "\n",
        "# Ricreare la cartella (opzionale)\n",
        "os.makedirs(directory, exist_ok=True)\n",
        "print(f\"La cartella '{directory}' è stata ricreata.\")\n",
        "\n",
        "# Convertire i DataFrame in Dataset di Hugging Face\n",
        "def convert_to_dataset(df):\n",
        "    return Dataset.from_pandas(df)\n",
        "\n",
        "# Supponiamo che train_df, val_df, e test_df siano già definiti\n",
        "train_dataset = convert_to_dataset(train_df)\n",
        "val_dataset = convert_to_dataset(val_df)\n",
        "test_dataset = convert_to_dataset(test_df)\n",
        "\n",
        "# Creare un DatasetDict\n",
        "dataset = DatasetDict({\n",
        "    'train': train_dataset,\n",
        "    'validation': val_dataset,\n",
        "    'test': test_dataset\n",
        "})\n",
        "\n",
        "# Preprocessare e tokenizzare\n",
        "model_name = \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    texts = [\n",
        "        (claim if claim is not None else \"\") + \" \" + (justification if justification is not None else \"\")\n",
        "        for claim, justification in zip(examples['Claim'], examples['Justification'])\n",
        "    ]\n",
        "    labels = [0 if label == 'Yes' else 1 if label == 'NEI' else 2 for label in examples['True Label']]\n",
        "\n",
        "    # Specifica la lunghezza massima\n",
        "    encodings = tokenizer(texts, padding=\"max_length\", truncation=True, max_length=128)\n",
        "\n",
        "    encodings['labels'] = labels\n",
        "    return encodings\n",
        "\n",
        "encoded_dataset = dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "# Configurare il modello\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)\n",
        "\n",
        "# Definire gli argomenti di training\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=4e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=5,\n",
        "    weight_decay=0.20,\n",
        "    gradient_accumulation_steps=2,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\",\n",
        "    save_strategy=\"epoch\"\n",
        ")\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.data = param.data.contiguous()\n",
        "\n",
        "# Definire la funzione di metriche\n",
        "def compute_metrics(p):\n",
        "    preds = np.argmax(p.predictions, axis=1)\n",
        "    precision = precision_score(p.label_ids, preds, average='weighted')\n",
        "    recall = recall_score(p.label_ids, preds, average='weighted')\n",
        "    f1 = f1_score(p.label_ids, preds, average='weighted')\n",
        "    accuracy = accuracy_score(p.label_ids, preds)\n",
        "    return {'precision': precision, 'recall': recall, 'f1': f1, 'accuracy': accuracy}\n",
        "\n",
        "# Creare il Trainer con specifica della funzione di perdita\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=encoded_dataset['train'],\n",
        "    eval_dataset=encoded_dataset['validation'],\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "# Addestrare il modello\n",
        "trainer.train()\n",
        "\n",
        "# Valutazione del modello sul set di test\n",
        "metrics = trainer.evaluate(encoded_dataset['test'])\n",
        "print(\"Test set evaluation metrics:\", metrics)"
      ],
      "metadata": {
        "id": "mmHn1DYB2hB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BioASQ"
      ],
      "metadata": {
        "id": "9rd83NPO2isG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "file_path = '/content/drive/MyDrive/Fine_Tuning/train.csv'\n",
        "file_path1 = '/content/drive/MyDrive/Fine_Tuning/val.csv'\n",
        "file_path2 = '/content/drive/MyDrive/Fine_Tuning/test.csv'\n",
        "#train1 sono 3 classi\n",
        "train_df = pd.read_csv(file_path)\n",
        "val_df = pd.read_csv(file_path1)\n",
        "test_df = pd.read_csv(file_path2)"
      ],
      "metadata": {
        "id": "uaj8Jmsz2kON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datasets import Dataset, DatasetDict\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# Percorso della cartella\n",
        "directory = './results'\n",
        "\n",
        "# Cancellare tutti i file e le sottocartelle\n",
        "if os.path.exists(directory):\n",
        "    shutil.rmtree(directory)\n",
        "    print(f\"Tutti i contenuti della cartella '{directory}' sono stati cancellati.\")\n",
        "else:\n",
        "    print(f\"La cartella '{directory}' non esiste.\")\n",
        "\n",
        "# Ricreare la cartella (opzionale)\n",
        "os.makedirs(directory, exist_ok=True)\n",
        "print(f\"La cartella '{directory}' è stata ricreata.\")\n",
        "\n",
        "# Convertire i DataFrame in Dataset di Hugging Face\n",
        "def convert_to_dataset(df):\n",
        "    return Dataset.from_pandas(df)\n",
        "\n",
        "# Supponiamo che train_df, val_df, e test_df siano già definiti\n",
        "train_dataset = convert_to_dataset(train_df)\n",
        "val_dataset = convert_to_dataset(val_df)\n",
        "test_dataset = convert_to_dataset(test_df)\n",
        "\n",
        "# Creare un DatasetDict\n",
        "dataset = DatasetDict({\n",
        "    'train': train_dataset,\n",
        "    'validation': val_dataset,\n",
        "    'test': test_dataset\n",
        "})\n",
        "\n",
        "# Preprocessare e tokenizzare\n",
        "model_name = \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    texts = [\n",
        "        (claim if claim is not None else \"\") + \" \" + (justification if justification is not None else \"\")\n",
        "        for claim, justification in zip(examples['Claim'], examples['Justification'])\n",
        "    ]\n",
        "    labels = [0 if label == 'Yes' else 1 for label in examples['True label']]\n",
        "\n",
        "    # Specifica la lunghezza massima\n",
        "    encodings = tokenizer(texts, padding=\"max_length\", truncation=True, max_length=128)\n",
        "\n",
        "    encodings['labels'] = labels\n",
        "    return encodings\n",
        "\n",
        "encoded_dataset = dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "# Configurare il modello\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)\n",
        "\n",
        "# Definire gli argomenti di training\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=4e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=5,\n",
        "    weight_decay=0.20,\n",
        "    gradient_accumulation_steps=2,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\",\n",
        "    save_strategy=\"epoch\"\n",
        ")\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.data = param.data.contiguous()\n",
        "\n",
        "# Definire la funzione di metriche\n",
        "def compute_metrics(p):\n",
        "    preds = np.argmax(p.predictions, axis=1)\n",
        "    precision = precision_score(p.label_ids, preds, average='weighted')\n",
        "    recall = recall_score(p.label_ids, preds, average='weighted')\n",
        "    f1 = f1_score(p.label_ids, preds, average='weighted')\n",
        "    accuracy = accuracy_score(p.label_ids, preds)\n",
        "    return {'precision': precision, 'recall': recall, 'f1': f1, 'accuracy': accuracy}\n",
        "\n",
        "# Creare il Trainer con specifica della funzione di perdita\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=encoded_dataset['train'],\n",
        "    eval_dataset=encoded_dataset['validation'],\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "# Addestrare il modello\n",
        "trainer.train()\n",
        "\n",
        "# Valutazione del modello sul set di test\n",
        "metrics = trainer.evaluate(encoded_dataset['test'])\n",
        "print(\"Test set evaluation metrics:\", metrics)\n"
      ],
      "metadata": {
        "id": "BrXCZjOh2m6Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}